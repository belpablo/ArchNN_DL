{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1tsIo4_Ie7Z1HcoW40uGr7EjqRAxdNluh",
     "timestamp": 1676027192692
    },
    {
     "file_id": "1DclfoEyYx9kJT7t9wv3qJBk8lAiqJKTs",
     "timestamp": 1675943068085
    },
    {
     "file_id": "1MtXqEaUAf7yn4uUsGZMVWURBZ9RKzcZE",
     "timestamp": 1665752404652
    }
   ],
   "collapsed_sections": [
    "6W-qyOTPct9-",
    "-3P3iL68dm21",
    "H_2lnqdFHG-r",
    "2HEtgbfUJJd8",
    "IXTSVYbfNSZU",
    "8_G6jrftZOsr",
    "FX-vmw5tb6jU",
    "APlEpRyTgFST",
    "YlvtVVDmgcv6",
    "Q7EFV0g-i48a",
    "6HKHRg8UkLfz"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "95506c0ffb5142fa8bfe64c999e73bac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cfa8b1ee019471c8892978121bdc3ae",
       "IPY_MODEL_13b1ee65b87440a1b871ef51a3bba18e",
       "IPY_MODEL_66f2991e16ea4f36b78c1fd092f16418"
      ],
      "layout": "IPY_MODEL_cf5a463c17b14428b5fe70ec468e51fd"
     }
    },
    "3cfa8b1ee019471c8892978121bdc3ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e514a3eae484234b26588660bbfdc98",
      "placeholder": "​",
      "style": "IPY_MODEL_bf74f79c27ce41ccaebb38eb242bbc88",
      "value": "100%"
     }
    },
    "13b1ee65b87440a1b871ef51a3bba18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1f836217a264640b23d1f6bf07317e8",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3c4154e5b9b42a3a8c3e091d13b52a9",
      "value": 5000
     }
    },
    "66f2991e16ea4f36b78c1fd092f16418": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bba90456094a434bbceade95b03ec064",
      "placeholder": "​",
      "style": "IPY_MODEL_1d51102c3c26467dbbb80aea38bb2767",
      "value": " 5000/5000 [00:23&lt;00:00, 340.73it/s]"
     }
    },
    "cf5a463c17b14428b5fe70ec468e51fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e514a3eae484234b26588660bbfdc98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf74f79c27ce41ccaebb38eb242bbc88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1f836217a264640b23d1f6bf07317e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3c4154e5b9b42a3a8c3e091d13b52a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bba90456094a434bbceade95b03ec064": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d51102c3c26467dbbb80aea38bb2767": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1. PyTorch introductory assignments\n",
    "\n",
    "PyTorch exercises for those who want to remember the basics of framefork."
   ],
   "metadata": {
    "id": "6W-qyOTPct9-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# main framework\n",
    "import torch\n",
    "# additional functions on tensors or networks\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# work with arrays in pure python\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "KobPC6g8cxPN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Tensors creation\n",
    "Tensors is a data structure optimized for automatic differentiation. In most cases, working with them is similar to working with arrays in numpy.\n",
    "\n",
    "We use `torch.tensor()` to create tensor object from pure Python and Numpy objects."
   ],
   "metadata": {
    "id": "-3P3iL68dm21",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. From list"
   ],
   "metadata": {
    "id": "H_2lnqdFHG-r",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch._C import dtype\n",
    "data_lst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "tensor_from_lst = torch.tensor(data_lst, dtype=torch.int64)"
   ],
   "metadata": {
    "id": "Q44dHwvGdgtV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor_from_lst.dtype == torch.int64)\n",
    "assert(tensor_from_lst.shape == torch.Size([3, 3]))"
   ],
   "metadata": {
    "id": "mjwKxHWyIAGT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. From Numpy array\n",
    "\n"
   ],
   "metadata": {
    "id": "2HEtgbfUJJd8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_ndarray = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "tensor_from_numpy = torch.tensor(data_ndarray)"
   ],
   "metadata": {
    "id": "B3JJ7L7jJiaL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor_from_numpy.dtype == torch.int64)\n",
    "assert(tensor_from_numpy.shape == torch.Size([3, 3]))"
   ],
   "metadata": {
    "id": "HDoWDqiPKXAT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also try to use `torch.from_numpy()` on the following array to understand the differences between this function and `torch.tensor()`"
   ],
   "metadata": {
    "id": "0y6JfgzAKYxb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_ndarray2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "tensor_using_from_numpy = torch.from_numpy(data_ndarray2)"
   ],
   "metadata": {
    "id": "dIewLwK3Kxbj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_from_numpy *= 0\n",
    "tensor_using_from_numpy *= 0"
   ],
   "metadata": {
    "id": "KqJs5outLhCb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(all(data_ndarray[0] == [1, 2, 3]))\n",
    "assert(all(data_ndarray2[0] == [0, 0, 0]))"
   ],
   "metadata": {
    "id": "OJQnlGPGMp9D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Using default values"
   ],
   "metadata": {
    "id": "IXTSVYbfNSZU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_shape = (2, 3, 4)\n",
    "\n",
    "# Creating a tensor of a given shape filled with zeros\n",
    "tensor_zeros = torch.zeros(data_shape)\n",
    "print('Zero:\\n{}'.format(tensor_zeros))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Hz-u_gYLr27",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547943763,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "68665924-7a10-4b18-8bd4-b108521ea840",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Zero:\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create tensor of a given shape filled with ones\n",
    "tensor_ones = torch.ones(data_shape)\n",
    "\n",
    "\n",
    "# Create tensor of a given shape filled with random numbers\n",
    "tensor_rand = torch.rand(data_shape)"
   ],
   "metadata": {
    "id": "JRj4ZOSCQz-E",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(all(tensor_ones[0][0] == torch.tensor([1., 1., 1., 1.])))\n",
    "assert(tensor_ones.shape == torch.Size(data_shape))\n",
    "assert(tensor_rand.shape == torch.Size(data_shape))"
   ],
   "metadata": {
    "id": "VORnV5CrSB1C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also create tensor from sequence using `torch.arange()` and then use `tensor.reshape()` function to convert data into the desired shape."
   ],
   "metadata": {
    "id": "6PfdPfD2RNkT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "range_len = 24\n",
    "# Create tensor filled with sequential values from 0 to range_len\n",
    "''' YOUR CODE HERE '''\n",
    "tensor_seq = torch.arange(range_len)\n",
    "\n",
    "# Convert the shape of the created tensor to fit data_shape\n",
    "''' YOUR CODE HERE '''\n",
    "tensor_seq_reshaped = torch.reshape(tensor_seq, data_shape)"
   ],
   "metadata": {
    "id": "4cBezVXLRNEs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor_seq[0] == torch.tensor(0))\n",
    "assert(tensor_seq[-1] == torch.tensor(range_len - 1))\n",
    "assert(tensor_seq.shape ==torch.Size([range_len]))"
   ],
   "metadata": {
    "id": "pfgHhd2jVItb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor_seq_reshaped[0][0][0] == torch.tensor(0))\n",
    "assert(tensor_seq_reshaped[-1][-1][-1] == torch.tensor(range_len - 1))\n",
    "assert(tensor_seq_reshaped.shape == torch.Size(data_shape))"
   ],
   "metadata": {
    "id": "6lD4IBMFRsEL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to make a tensor with a shape of another tensor, but with default values, you can use `torch.values_like()` functions"
   ],
   "metadata": {
    "id": "w8iarPvOXXXz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tensor = torch.rand((1, 2, 2))\n",
    "\n",
    "# For example, you want to create a mask for the image or something filled with zeros\n",
    "tensor_mask = torch.zeros_like(tensor)\n",
    "print('Image:\\n{}'.format(tensor))\n",
    "print('Image_mask:\\n{}'.format(tensor_mask))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiYRWNOMQJFk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547943764,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "faec71fa-c067-41ea-d7f7-b6078a0ec079",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image:\n",
      "tensor([[[0.2572, 0.2069],\n",
      "         [0.5841, 0.1806]]])\n",
      "Image_mask:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using similar functions, create a tensor mask filled with ones and a mask filled with the random values"
   ],
   "metadata": {
    "id": "-CQ-VUHgX7Ir",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Mask, filled with ones (with a shape of tensor)\n",
    "tensor_mask_ones = torch.ones_like(tensor)\n",
    "\n",
    "# Mask, filled with random values (with a shape of tensor)\n",
    "tensor_mask_rand = torch.rand_like(tensor_mask_ones)"
   ],
   "metadata": {
    "id": "62UbgUOzINGK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor_mask_ones[0][0][0] == torch.tensor(1.))\n",
    "assert(tensor_mask_ones.shape == tensor.shape)\n",
    "assert(tensor_mask_rand.shape == tensor.shape)"
   ],
   "metadata": {
    "id": "gAu-GFSiYaQp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Devices\n",
    "\n",
    "Tensors can be stored in general memory, GPU memory, TPU memory."
   ],
   "metadata": {
    "id": "8_G6jrftZOsr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tensor = torch.rand((2, 5, 5))\n",
    "print(tensor.device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpmBNwwPYu1R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547944683,
     "user_tz": -180,
     "elapsed": 925,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "dfcc1bac-44e5-446c-d1f2-e46cb8cacdf1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the further assignments you should use Google Colab with GPU (Runtime -> Change Runtime Type -> Hardware Accelerating) and store tensors in GPU memory."
   ],
   "metadata": {
    "id": "YUD2xWiTbc48",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "id": "wDOy0VX6bmDL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547944683,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "0e91a08c-d87f-4759-ac28-6ee20d186c8b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cuda'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Move tensor to the GPU memory\n",
    "tensor = tensor.to(device)"
   ],
   "metadata": {
    "id": "cteUw9WwaDT5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor.device.type == 'cuda')"
   ],
   "metadata": {
    "id": "rNMyYsp9abgS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Autograd\n",
    "\n",
    "Auto differentiation is a core of ML frameworks. PyTorch can figure out the computation of gradients for a set of operations. Almost all pytorch operations are differentiable.\n",
    "\n",
    "`required_grad=True` make PyTorch to store gradients for this particular tensor. Usually, for input values this parameters is set to False - we don't want to change our real data."
   ],
   "metadata": {
    "id": "FX-vmw5tb6jU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# tensor = torch.rand((2, 4, 4), requires_grad=True)\n",
    "tensor = torch.ones((2, 4, 4))\n",
    "tensor.requires_grad = True"
   ],
   "metadata": {
    "id": "I5gMYz1jas4J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# define function y\n",
    "y = 5 * tensor ** 3 - 3\n",
    "print(y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3mOapZqeKbJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946147,
     "user_tz": -180,
     "elapsed": 9,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "f5ce86cf-a946-467e-9952-35c38f0576de",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor.grad)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsQqec9DeMuB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946147,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "50d79cf1-3fe4-4b8d-e2ba-ef673a0702c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no gradient for our tensor, because we have to call `.backward() ` method of variable $y$. This method will calculate gradien of $y$ over variable tensor\n",
    "\n",
    "NOTE: gradient can be calculated only for a scalar. The output of $y$ is a tensor, we can calculate mean(), sum(), etc"
   ],
   "metadata": {
    "id": "r5Tnnn-5ehDE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Call the backward method and calculate gradient for the sum of the y variable\n",
    "y.sum().backward()\n",
    "tensor.grad"
   ],
   "metadata": {
    "id": "MTcL7kXSePLh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946148,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "30915519-624f-4b29-b683-51414e55ef0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.]],\n",
       "\n",
       "        [[15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [15., 15., 15., 15.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
    "assert(tensor.grad[0][0][0] == torch.tensor(15))"
   ],
   "metadata": {
    "id": "j4BbcuK-eRTJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NOTE:** \n",
    "* you can not run `.backward()` again without calculating y value again;\n",
    "* if you run y function one more time the gradient values for tensor variable will be summed."
   ],
   "metadata": {
    "id": "-N-xsoeofiFb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Call the backward method again and calculate gradient for the sum of the y variable\n",
    "y = 5 * tensor ** 3 - 3\n",
    "y.sum().backward()\n",
    "tensor.grad"
   ],
   "metadata": {
    "id": "zWjIrpwof4Pa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946148,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "386f213a-7097-411f-ad1e-cdfc252ab059",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.]],\n",
       "\n",
       "        [[30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.],\n",
       "         [30., 30., 30., 30.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
    "assert(tensor.grad[0][0][0] == torch.tensor(30))"
   ],
   "metadata": {
    "id": "yhve93SVfLsB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Neural network in PyTorch\n",
    "\n",
    "NN in PyTorch defines as a set of different layers. Each layer is a specific function:\n",
    "\n",
    "\n",
    "*   Linear layer, convolutional layer, etc\n",
    "*   Activation function\n",
    "*   Tensors operations\n",
    "\n",
    "The first type has parameters called weights and biases.The process of NN training is to change weights of NN layers so the prediction of network will match the real object.\n"
   ],
   "metadata": {
    "id": "APlEpRyTgFST",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear layer\n",
    "\n",
    "[torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) takes a matrix $(N, *, H_{in})$ and produce a matrix $(N, *, H_{out})$, where\n",
    "\n",
    "$*$ means any number of additional dimensions, $H_{in}$ - input features, $H_{out}$ - output features\n",
    "\n",
    "Linear layer is a $W \\cdot x + b$ operation, where $W$ - weights of the layer and $b$ - bias. Bias can be ommited with `bias=False`"
   ],
   "metadata": {
    "id": "YlvtVVDmgcv6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_tensor = torch.ones((3, 5))\n",
    "print('input shape: ', input_tensor.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8m8BLBtOfbT6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946148,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "60857076-86a7-4937-b9f3-d10d9a66353e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input shape:  torch.Size([3, 5])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We fed sample of data with batch_size=3 and features of each sample=5. \n",
    "\n",
    "All samples in a batch processed separately. This is true for all layers and functions of PyTorch."
   ],
   "metadata": {
    "id": "QQfOM30-hX37",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a linear layer for given data with the number of out_features=100 and ommited bias (don't forget about GPU)\n",
    "layer = torch.nn.Linear(5, 100, bias=False).to(\"cuda\")"
   ],
   "metadata": {
    "id": "CLpsiSGshFvb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a look at layers parameters. \n",
    "\n",
    "`layer.paramaters()` outputs a generator of all weights and biases of this object."
   ],
   "metadata": {
    "id": "qJepe-jlh5Pi",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(type(layer.parameters()))\n",
    "# iterate over layer parameters and print shapes\n",
    "for i in layer.parameters():\n",
    "    print(i.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GS3o9IikhJoQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946149,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "04270f2b-3824-47d9-e7b7-d4cdf7892890",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'generator'>\n",
      "torch.Size([100, 5])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should receive the following output:\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ],
   "metadata": {
    "id": "D6J6Gi3qiDIM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Single layer contains only one weight matrix of shape (H_out, H_in). You can access the weights of a layer directly, using `layer.weight` method"
   ],
   "metadata": {
    "id": "u7KbPhOUiSDj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(layer.weight.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oPpsDNRiB8T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946149,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "614a8e71-4509-480c-a3d4-3a3bcdc6c207",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 5])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can move layer from CPU to GPU in the same way as tensor."
   ],
   "metadata": {
    "id": "4xP6UY8GioBC",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "layer.to('cpu') # or layer.cpu() for simplicity"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlFkkXb4iZgB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946149,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "e6c2c99b-c2db-4118-d724-b4ffe2a7eeb0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=100, bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "layer.to('cuda:0')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_JICUxwisUh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946150,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "f796c839-1c22-4ba4-e21c-1375b6dfed1b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=100, bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network\n",
    "\n",
    "You can write a NN as a set of layers and then apply them sequentially"
   ],
   "metadata": {
    "id": "Q7EFV0g-i48a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn.modules.container import Sequential\n",
    "input_tensor = torch.rand((3, 5))\n",
    "\n",
    "# Create three sequential linear layers for the given input tensor. First two with the output 100 and the last one with the output 3.\n",
    "# Apply them sequentially and store in the output\n",
    "three_seq = Sequential(\n",
    "    torch.nn.Linear(5, 100, bias=False),\n",
    "    torch.nn.Linear(100, 100, bias=False),\n",
    "    torch.nn.Linear(100, 3, bias=False)\n",
    ")\n",
    "\n",
    "# approx 3 lines of code here\n",
    "\n",
    "output = three_seq(input_tensor)"
   ],
   "metadata": {
    "id": "Ab1xdz34iu5x",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(output.shape == torch.Size([3, 3]))"
   ],
   "metadata": {
    "id": "_zpoyRpZjEqp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Activation and loss functions"
   ],
   "metadata": {
    "id": "6HKHRg8UkLfz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use different activation functions from `torch.nn` and combine them sequentially with the NN layers"
   ],
   "metadata": {
    "id": "GwzcN4uGkXAM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example of the activation function\n",
    "torch.nn.ReLU6()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9J8DHXGjO1J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676547946150,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "e151b7c7-c932-4fc2-c867-a5d51b10ebd1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ReLU6()"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use different loss functions from `torch.nn`"
   ],
   "metadata": {
    "id": "AmXDvB9Hkq7D",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example of the loss fun\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "id": "CMv12O20krIq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2. Feedforward Neural Network construction assignment "
   ],
   "metadata": {
    "id": "04nXIR3jkA1c",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import all the necessary libraries"
   ],
   "metadata": {
    "id": "J3E6eNqIl5PM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "id": "TiLtxZ24mXBK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578312069,
     "user_tz": -180,
     "elapsed": 5152,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use the `plot_decision_regions` we should additionally install the `mlxtend` package"
   ],
   "metadata": {
    "id": "y8JoJwwamJPq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install mlxtend"
   ],
   "metadata": {
    "id": "VIAJAIG2l4Vq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578315452,
     "user_tz": -180,
     "elapsed": 3386,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "9d0a20c5-d927-42a3-f14d-7f6b76e447be",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uploading dataset\n",
    "\n",
    "Let's upload the wine dataset from sklearn"
   ],
   "metadata": {
    "id": "kN4gvrl5md66",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "wine = sklearn.datasets.load_wine()\n",
    "wine.data.shape"
   ],
   "metadata": {
    "id": "ElBSbXRBkKUr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578315453,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "1e5c50c9-1e88-4e00-c4ea-f4433f3a15be",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create class for the dataset. Inherit a class from Dataset"
   ],
   "metadata": {
    "id": "ZzmI_lNKs7M5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Fill the WineDataset class fields\n",
    "\n",
    "class WineDataset():\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).to(device)\n",
    "        self.y = torch.from_numpy(y).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "ds = WineDataset(wine.data, wine.target)\n",
    "for x, y in ds:\n",
    "  print(x, y)\n",
    "  break"
   ],
   "metadata": {
    "id": "1oTZKhTymtUE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578320467,
     "user_tz": -180,
     "elapsed": 5018,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6cf6e221-c2e9-431a-c0fb-006d65b78eb4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03], device='cuda:0', dtype=torch.float64) tensor(0, device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create train and test splits using `train_test_split` function with the following parameters:\n",
    "\n",
    "* size of test - 30%\n",
    "* using shuffle\n",
    "* using SEED constant for the random state\n",
    "\n",
    "Remember that use should use WineDataset class."
   ],
   "metadata": {
    "id": "wzd8eZoUtrL5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine.data,\n",
    "                                                    wine.target,\n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=SEED)\n",
    "\n",
    "train_dataset = WineDataset(X_train, y_train)\n",
    "test_dataset = WineDataset(X_test, y_test)"
   ],
   "metadata": {
    "id": "-rizvl_0tiBq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578320468,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(len(train_dataset) == 124)\n",
    "assert(len(test_dataset) == 54)"
   ],
   "metadata": {
    "id": "t3hIxoW7uY-D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578320469,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Feedforward network\n",
    "\n",
    "Create the FNN with the following attributes:\n",
    "* 3 linear layers\n",
    "* activation functions on your choice (the most suitable for this kind of task)"
   ],
   "metadata": {
    "id": "4-qto2JZuw4p",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "INPUT_SIZE = wine.data.shape[1]\n",
    "OUTPUT_SIZE = max(wine.target) + 1\n",
    "\n",
    "\n",
    "class WineNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in=INPUT_SIZE, n_hidden_neurons=100, n_out=OUTPUT_SIZE):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.three_lin_layers_seq = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden_neurons, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden_neurons, n_hidden_neurons, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden_neurons, n_out, bias=True),\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.three_lin_layers_seq(x)\n",
    "        x = F.log_softmax(x, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # для использования в функции plot_decision_regions\n",
    "    def predict(self, x):\n",
    "\n",
    "        ''' PLEASE DO NOT CHANGE THE CODE OF THIS FUNCTION '''\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "\n",
    "        x = x.cpu().argmax(dim=-1)\n",
    "        x = x.data.numpy()\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "id": "J80UqErYuZAL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578320469,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# you can change parameters here\n",
    "\n",
    "model = WineNet(n_hidden_neurons = 100) \n",
    "model = model.to(device)\n",
    "\n",
    "for x, y in train_dataset:\n",
    "  print(model(x.float()))\n",
    "  break"
   ],
   "metadata": {
    "id": "TCFnDMR3vl_a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578321275,
     "user_tz": -180,
     "elapsed": 813,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95e03fa7-7969-4403-9558-5f70fdd97b61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-36.7317, -30.7401,   0.0000], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training FNN"
   ],
   "metadata": {
    "id": "JB3p3LdpwAdR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize the loss function and initialize and tune the optimizer and scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.KLDivLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "#scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)"
   ],
   "metadata": {
    "id": "SU5dJkJZv6m5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578322652,
     "user_tz": -180,
     "elapsed": 1379,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write the code for the model training process.\n",
    "\n",
    "NOTE: You can memorize the best metric value and weight in the colab with the commands \n",
    "\n",
    "`torch.save(model.state_dict(), STATE_DICT_PATH)`, and `load model.load_state_dict(torch.load(STATE_DICT_PATH))`"
   ],
   "metadata": {
    "id": "aBn87Xy0xNSS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = WineNet(n_hidden_neurons = 100) \n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS_NUM = 5000\n",
    "\n",
    "''' PLEASE DO NOT CHANGE THE CODE OF THESE LINES '''\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "metric_fn = lambda true, pred: metrics.f1_score(true, pred, average='macro')\n",
    "best_metric_value = 0.87\n",
    "STATE_DICT_PATH = 'best_model_state_dict.pt'\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS_NUM)):\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x.float()), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if scheduler:\n",
    "      scheduler.step(loss)\n",
    "        \n",
    "    if (epoch * 10) % EPOCHS_NUM == 0:\n",
    "        model.eval()\n",
    "        test_preds, true = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                preds = model(x.float())\n",
    "                test_preds.append(preds)\n",
    "                true.append(y)\n",
    "        \n",
    "        test_preds = torch.cat(test_preds).squeeze()\n",
    "        true = torch.cat(true).squeeze()\n",
    "        test_loss = loss_fn(test_preds, true).item()\n",
    "        test_metric = metric_fn(true.to(\"cpu\"),\n",
    "                                test_preds.argmax(dim=-1).to(\"cpu\"))\n",
    "        \n",
    "        print(f'Epoch: {epoch}\\t\\tTest loss: {test_loss:0.4f}\\t\\tTest metric: {test_metric:0.4f}')\n",
    "\n",
    "        if (test_metric >= 0.87) and (test_metric > best_metric_value):\n",
    "            torch.save(model.state_dict(), STATE_DICT_PATH)\n",
    "            best_metric_value = test_metric\n",
    "            print(\"New score achieved. Model state dict was updated.\\n\")\n"
   ],
   "metadata": {
    "id": "JB7wbCFuwSIh",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "95506c0ffb5142fa8bfe64c999e73bac",
      "3cfa8b1ee019471c8892978121bdc3ae",
      "13b1ee65b87440a1b871ef51a3bba18e",
      "66f2991e16ea4f36b78c1fd092f16418",
      "cf5a463c17b14428b5fe70ec468e51fd",
      "5e514a3eae484234b26588660bbfdc98",
      "bf74f79c27ce41ccaebb38eb242bbc88",
      "b1f836217a264640b23d1f6bf07317e8",
      "a3c4154e5b9b42a3a8c3e091d13b52a9",
      "bba90456094a434bbceade95b03ec064",
      "1d51102c3c26467dbbb80aea38bb2767"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578345233,
     "user_tz": -180,
     "elapsed": 22587,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "3434f12a-822c-48d1-d230-4699ad646400",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95506c0ffb5142fa8bfe64c999e73bac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0\t\tTest loss: 32.2907\t\tTest metric: 0.1735\n",
      "Epoch: 500\t\tTest loss: 0.1583\t\tTest metric: 0.9469\n",
      "New score achieved. Model state dict was updated.\n",
      "\n",
      "Epoch: 1000\t\tTest loss: 0.1552\t\tTest metric: 0.9303\n",
      "Epoch: 1500\t\tTest loss: 0.1226\t\tTest metric: 0.9469\n",
      "Epoch: 2000\t\tTest loss: 0.1154\t\tTest metric: 0.9469\n",
      "Epoch: 2500\t\tTest loss: 0.1167\t\tTest metric: 0.9469\n",
      "Epoch: 3000\t\tTest loss: 0.1295\t\tTest metric: 0.9469\n",
      "Epoch: 3500\t\tTest loss: 0.1417\t\tTest metric: 0.9469\n",
      "Epoch: 4000\t\tTest loss: 0.1545\t\tTest metric: 0.9469\n",
      "Epoch: 4500\t\tTest loss: 0.1637\t\tTest metric: 0.9469\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "metrics.f1_score(true.to(\"cpu\"), \n",
    "                 test_preds.argmax(dim=-1).to(\"cpu\"),\n",
    "                 average='macro')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkLidUW8DCba",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578345233,
     "user_tz": -180,
     "elapsed": 5,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "34691519-5ba4-46f8-e078-3ee4fd433cd1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9468546473850431"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example of the nice data plot :)"
   ],
   "metadata": {
    "id": "ZCsjlTrJxu6p",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# display decision region for all elements\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "value=1.5\n",
    "width=0.75\n",
    "\n",
    "model.eval()\n",
    "plt.rcParams['figure.figsize'] = (130, 130)\n",
    "\n",
    "X = wine.data #[:, :2] # fix here if needed\n",
    "y = wine.target\n",
    "\n",
    "fig, axs = plt.subplots(13, 13)\n",
    "\n",
    "for i in range(13):\n",
    "  for j in range(13):\n",
    "    features = [i, j]\n",
    "    #plt.subplot(i + 1, j + 1)\n",
    "    plot_decision_regions(X, y, clf=model, \n",
    "                          feature_index = features,\n",
    "                          filler_feature_values = {i : value for i in range(13) if i not in features},\n",
    "                          filler_feature_ranges = {i : width for i in range(13) if i not in features},\n",
    "                          legend = 2, ax = axs[i, j])\n",
    "\n",
    "#Why this does not work? Why none of them are informative?"
   ],
   "metadata": {
    "id": "tFuu3GCjxo7K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation\n",
    "\n",
    "You should create a model with the F1-score greater than 0.87"
   ],
   "metadata": {
    "id": "oaF116Zdxsax",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        preds = model.forward(x.float()).cpu()\n",
    "        test_preds.append(preds)\n",
    "        true.append(y)\n",
    "test_preds = torch.cat(test_preds).squeeze()\n",
    "true = torch.cat(true).squeeze()\n",
    "test_metric = metrics.f1_score(true.to(\"cpu\"), \n",
    "                               test_preds.argmax(dim=-1).to(\"cpu\"),\n",
    "                               average='macro')\n",
    "\n",
    "print('F1-score on test:', test_metric)\n",
    "assert test_metric >= 0.87, \"You need to get f1_score greater or equal to 0.87\""
   ],
   "metadata": {
    "id": "N4Qal9n4x5ca",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676578348870,
     "user_tz": -180,
     "elapsed": 426,
     "user": {
      "displayName": "Pavel Belenko",
      "userId": "01154748966313521845"
     }
    },
    "outputId": "7e09ba80-9b19-4722-f5ff-30ee1ccbb038",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score on test: 0.9468546473850431\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "pB1Lzkp3XdFm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}